# Gesture-to-Text for Differently Abled

This project focuses on hand gesture recognition using OpenCV and Python, with an emphasis on real-time video processing. The goal is to detect and classify hand gestures, addressing challenges such as pose variation, lighting conditions, and noise.

The process involves multiple stages: image acquisition, pre-processing, feature extraction, and gesture recognition. Image acquisition captures video frames from a webcam, and pre-processing includes tasks like colour filtering, smoothing, and thresholding. Feature extraction involves identifying hand contours, while gesture recognition classifies gestures based on these features.
Detecting the hand in real-time video poses challenges like unstable brightness, noise, poor resolution, and contrast. Segmentation and edge detection, considering colour, hand posture, and shape, are crucial for accurate gesture recognition.

The project tackles two main issues: hand detection and gesture recognition. Hand detection relies on webcam input, facing challenges of brightness, noise, and contrast. Gesture recognition involves segmentation, edge detection, and consideration of colour, hand posture, and shape in real time. Additionally creating suitable signs for one-handed use involves extracting hand contours and addressing convexity defects, which require depth calculation equations.

DATA SET:-
![image](https://github.com/AkashPatilkulkarni/Gesture-to-Text/assets/139881101/3004f35b-1add-486b-8f1e-c1ba579ebcef)

OUTPUTS:-

![Picture1](https://github.com/AkashPatilkulkarni/Gesture-To-Text-for-Differently-Abled/assets/139881101/39de9a63-6cf4-4ad6-bf97-eddf12aa031d)

![Picture2](https://github.com/AkashPatilkulkarni/Gesture-To-Text-for-Differently-Abled/assets/139881101/1efbddd6-a2c2-433a-a786-bc847f076420)
